<!--
## Papers

### Already read/skimmed:

<ul style="margin:0 0 20px;">
  <li><a href="https://conferences.miccai.org/2022/papers/398-Paper0362.html"><autocolor>Progression models for imaging data with Longitudinal Variational Auto Encoders</autocolor></a></li>
  <li>to update</li>
</ul>


 ### On my reading list:

<!-- <h4 style="margin:0 10px 0;">Journal Reviewers</h4>

<ul style="margin:0 0 20px;">
   <li><a href="https://openreview.net/pdf?id=HJgSwyBKvr"><autocolor>Weakly Supervised Disentanglement with Guarantees</autocolor></a></li>
  <li><a href="https://arxiv.org/pdf/1506.02557.pdf"><autocolor>Variational Dropout and
the Local Reparameterization Trick</autocolor></a></li>
  <li><a href="https://proceedings.mlr.press/v139/mita21a.html"><autocolor>An Identifiable Double VAE For Disentangled Representations</autocolor></a></li>
   <li><a href="https://discovery.ucl.ac.uk/id/eprint/10148091/2/phd_thesis_ilyes_khemakhem_17121553_final.pdf"><autocolor>Advances in Identifiability of Nonlinear Probabilistic Models (Ilyes Khemakhem' thesis)</autocolor></a></li>
  <li> <a href="https://arxiv.org/abs/2007.00810"><autocolor>On Linear Identifiability of Learned Representations</autocolor></a></li>
  <li> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8784019/"><autocolor>Should I use fixed effects or random effects when I have fewer than five levels of a grouping factor in a mixed-effects model?</autocolor></a></li>
  <li> <a href="https://www.jstor.org/stable/2685526"><autocolor>Conditional Linear Mixed Models</autocolor></a></li> 
</ul> 




